{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c616845f-6481-4700-a542-038633a92f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import TextFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86932224-203b-429f-b40b-c8e1b547b299",
   "metadata": {},
   "source": [
    "# GET YOUR OWN API KEY WITH BELOW INSTRUCTIONS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43ce1c00-4a2c-44dd-93dc-df8c00d5f052",
   "metadata": {},
   "source": [
    "# Go to Google Cloud Console (https://console.cloud.google.com/welcome?project=precise-data-392110&pli=1).\n",
    "# Click on the project drop-down at the top, then “New Project”.\n",
    "# Enter a project name and click “Create”.\n",
    "# In the Google Cloud Console, navigate to “APIs & Services” > “Library”.\n",
    "# Search for “YouTube Data API v3” and click on it.\n",
    "# Click “Enable”.\n",
    "# Go to “APIs & Services” > “Credentials”.\n",
    "# Click “+ CREATE CREDENTIALS” and select “API key”.\n",
    "# Copy the generated API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37cf8221-2f6b-4355-b14e-4fd5984adfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your own API key\n",
    "API_KEY = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37c4ae-8e06-4130-a453-85d0e0de0b42",
   "metadata": {},
   "source": [
    "# COLLECT ALL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808cb43-cb37-4f33-9098-8cdfec18007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def youtube_search(query, max_results=10, published_after=None):\n",
    "    \"\"\"Search for videos on YouTube.\"\"\"\n",
    "    youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "    \n",
    "    search_response = youtube.search().list(\n",
    "        q=query,\n",
    "        part=\"id,snippet\",\n",
    "        maxResults=max_results,\n",
    "        type=\"video\",  # Only return video results\n",
    "        publishedAfter=published_after  # Filter by published date if provided\n",
    "    ).execute()\n",
    "\n",
    "    video_links = []\n",
    "    for item in search_response.get(\"items\", []):\n",
    "        video_id = item[\"id\"][\"videoId\"]\n",
    "        video_title = item[\"snippet\"][\"title\"]\n",
    "        video_link = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "        date_posted = item[\"snippet\"][\"publishedAt\"].split(\"T\")[0]  # Extract date without timestamp\n",
    "        video_links.append((video_id, video_title, video_link, date_posted))\n",
    "\n",
    "    return video_links\n",
    "\n",
    "def get_comments(video_id, max_comments=10):\n",
    "    \"\"\"Retrieve the last N comments for a given video ID.\"\"\"\n",
    "    youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "    comments = []\n",
    "    page_token = None\n",
    "    \n",
    "    try:\n",
    "        while len(comments) < max_comments:\n",
    "            response = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                textFormat=\"plainText\",\n",
    "                maxResults=min(max_comments - len(comments), 100),  # Adjust to not exceed max_comments\n",
    "                order='time',\n",
    "                pageToken=page_token\n",
    "            ).execute()\n",
    "\n",
    "            # Fetch comments and format them with numbering\n",
    "            for idx, item in enumerate(response.get(\"items\", [])):\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                comments.append(f\"{len(comments) + 1}. {comment}\")  # Format with numbering\n",
    "            \n",
    "            # Check if there are more comments to fetch\n",
    "            page_token = response.get(\"nextPageToken\")\n",
    "            if not page_token:  # Exit if there are no more pages\n",
    "                break\n",
    "\n",
    "    except HttpError as e:\n",
    "        if e.resp.status == 403:\n",
    "            return [\"Comments are disabled for this video.\"]\n",
    "        else:\n",
    "            return [f\"Error fetching comments: {e}\"]\n",
    "\n",
    "    return comments[:max_comments]  # Return only up to max_comments\n",
    "\n",
    "def download_transcript(video_id):\n",
    "    \"\"\"\n",
    "    Download the transcript, translate to English if necessary, and return as a string.\n",
    "    Args:\n",
    "        video_id (str): The YouTube video ID.\n",
    "    Returns:\n",
    "        str: The transcript text in English or an empty string if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve available transcripts\n",
    "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "        \n",
    "        transcript = None\n",
    "\n",
    "        # Try to find a manually created or generated transcript in English first\n",
    "        try:\n",
    "            transcript = transcript_list.find_transcript(['en'])\n",
    "        except:\n",
    "            try:\n",
    "                # Fall back to generated transcript if manually created isn't available\n",
    "                transcript = transcript_list.find_generated_transcript(['en'])\n",
    "            except:\n",
    "                # If no English transcript, pick the first available transcript in any language\n",
    "                for available_transcript in transcript_list:\n",
    "                    if available_transcript.is_translatable:\n",
    "                        transcript = available_transcript\n",
    "                        break\n",
    "        \n",
    "        if transcript is None:\n",
    "            raise Exception(\"No translatable transcript available\")\n",
    "\n",
    "        # If transcript isn't in English, translate it to English\n",
    "        if transcript.language_code != 'en':\n",
    "            transcript = transcript.translate('en')\n",
    "        \n",
    "        # Fetch the transcript and format it\n",
    "        formatter = TextFormatter()\n",
    "        transcript_text = formatter.format_transcript(transcript.fetch())\n",
    "\n",
    "        # Clean up the transcript by removing timecodes and speaker names\n",
    "        transcript_text = re.sub(r'\\[\\d+:\\d+:\\d+\\]', '', transcript_text)\n",
    "        transcript_text = re.sub(r'<\\w+>', '', transcript_text)\n",
    "        transcript_text = re.sub(r'\\s+', ' ', transcript_text).strip()\n",
    "\n",
    "        return transcript_text\n",
    "    except Exception as e:\n",
    "        # print(f\"Error downloading transcript: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    \"\"\"Sanitize a filename by removing or replacing invalid characters.\"\"\"\n",
    "    # Remove characters that are invalid for filenames\n",
    "    sanitized = re.sub(r'[<>:\"/\\\\|?*]', '', filename)\n",
    "    \n",
    "    # Optionally replace spaces with underscores (optional)\n",
    "    sanitized = sanitized.replace(' ', '_')\n",
    "    \n",
    "    # Keep only alphanumeric characters, spaces, underscores, and hyphens\n",
    "    return \"\".join(c for c in sanitized if c.isalnum() or c in ('_', '-')).rstrip()\n",
    "\n",
    "def main():\n",
    "    user_query = input(\"Enter a search term for YouTube: \")\n",
    "\n",
    "    num_videos_input = input(\"Enter the number of videos to retrieve (or 'all' for maximum): \")\n",
    "    num_videos = 50 if num_videos_input.lower() == \"all\" else int(num_videos_input)\n",
    "\n",
    "    num_comments_input = input(\"Enter the number of comments to retrieve for each video (or 'all' for maximum): \")\n",
    "    num_comments = 100 if num_comments_input.lower() == \"all\" else int(num_comments_input)\n",
    "\n",
    "    years_back = int(input(\"How many years back do you want to search for videos? \"))\n",
    "    published_after_date = (datetime.now() - timedelta(days=years_back * 365)).isoformat(\"T\") + \"Z\"\n",
    "\n",
    "    # Ask the user for the directory where they want to save the output file\n",
    "    save_directory = input(\"Enter the directory path where you'd like to save the output file: \").strip()\n",
    "\n",
    "    # Search for videos\n",
    "    video_links = youtube_search(user_query, num_videos, published_after=published_after_date)\n",
    "\n",
    "    # Prepare data for DataFrame\n",
    "    data = []\n",
    "\n",
    "    if video_links:\n",
    "        for video_id, title, link, date_posted in video_links:\n",
    "            # Get last N comments for each video\n",
    "            comments = get_comments(video_id, num_comments)\n",
    "            comments_text = '\\n'.join(comments)  # Join comments into a single string, one per line\n",
    "\n",
    "            # Get transcript for each video\n",
    "            transcript_text = download_transcript(video_id)\n",
    "            transcript_text = transcript_text if transcript_text else \"Transcript not available.\"\n",
    "\n",
    "            # Append data\n",
    "            data.append({\n",
    "                \"Serial Number\": len(data) + 1,\n",
    "                \"Video Name\": title,\n",
    "                \"Video Link\": link,\n",
    "                \"Date Posted\": date_posted,\n",
    "                \"Comments\": comments_text,\n",
    "                \"Transcript\": transcript_text\n",
    "            })\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Sanitize the filename and create the full output path\n",
    "        sanitized_query = sanitize_filename(user_query)\n",
    "        output_file = os.path.join(save_directory, f\"{sanitized_query}_YouTube_Data.xlsx\")\n",
    "\n",
    "        # Save to Excel\n",
    "        df.to_excel(output_file, index=False)\n",
    "\n",
    "        print(f\"Data saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No videos found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab684770-4fa2-4ec1-978c-8b6c6c86348a",
   "metadata": {},
   "source": [
    "MAXIMUN COMMENTS RETRIEVED ARE 100\n",
    "MAXIMUN VIDEOS RETRIEVED ARE 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9373a7d6-3421-428d-bed2-d7d8668765ea",
   "metadata": {},
   "source": [
    "# COLLECT TRANSCRIPT ONLY USING VIDEO LINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48cbcc17-4fbf-41f8-a4c3-f4c7742a6178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the YouTube video link:  https://www.youtube.com/watch?v=kSmcQiO7z4Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript saved to kSmcQiO7z4Y_Complete Power BI tutorial for Beginners 2024 🚀🚀(All material 🎁 included).txt\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import TextFormatter\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "\n",
    "def get_video_id(youtube_url):\n",
    "    \"\"\"\n",
    "    Extract the video ID from a YouTube URL.\n",
    "    Args:\n",
    "        youtube_url (str): The YouTube URL.\n",
    "    Returns:\n",
    "        str: The extracted video ID or None if not found.\n",
    "    \"\"\"\n",
    "    pattern = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
    "    match = re.search(pattern, youtube_url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def get_video_title(video_id):\n",
    "    \"\"\"\n",
    "    Get the title of the YouTube video.\n",
    "    Args:\n",
    "        video_id (str): The YouTube video ID.\n",
    "    Returns:\n",
    "        str: The title of the video or \"Unknown\" if not found.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        matches = re.findall(r'<title>(.*?)</title>', response.text)\n",
    "        return matches[0].replace(\" - YouTube\", \"\") if matches else \"Unknown\"\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching video title: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "def download_transcript(video_id):\n",
    "    \"\"\"\n",
    "    Download the transcript, translate to English if necessary, and return as a string.\n",
    "    Args:\n",
    "        video_id (str): The YouTube video ID.\n",
    "    Returns:\n",
    "        str: The transcript text in English or an empty string if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve available transcripts\n",
    "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "        \n",
    "        transcript = None\n",
    "\n",
    "        # Try to find a manually created or generated transcript in English first\n",
    "        try:\n",
    "            transcript = transcript_list.find_transcript(['en'])\n",
    "        except:\n",
    "            try:\n",
    "                # Fall back to generated transcript if manually created isn't available\n",
    "                transcript = transcript_list.find_generated_transcript(['en'])\n",
    "            except:\n",
    "                # If no English transcript, pick the first available transcript in any language\n",
    "                for available_transcript in transcript_list:\n",
    "                    if available_transcript.is_translatable:\n",
    "                        transcript = available_transcript\n",
    "                        break\n",
    "        \n",
    "        if transcript is None:\n",
    "            raise Exception(\"No translatable transcript available\")\n",
    "\n",
    "        # If transcript isn't in English, translate it to English\n",
    "        if transcript.language_code != 'en':\n",
    "            transcript = transcript.translate('en')\n",
    "        \n",
    "        # Fetch the transcript and format it\n",
    "        formatter = TextFormatter()\n",
    "        transcript_text = formatter.format_transcript(transcript.fetch())\n",
    "\n",
    "        # Clean up the transcript by removing timecodes and speaker names\n",
    "        transcript_text = re.sub(r'\\[\\d+:\\d+:\\d+\\]', '', transcript_text)\n",
    "        transcript_text = re.sub(r'<\\w+>', '', transcript_text)\n",
    "        transcript_text = re.sub(r'\\s+', ' ', transcript_text).strip()\n",
    "\n",
    "        return transcript_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading transcript: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    youtube_url = input(\"Enter the YouTube video link: \")\n",
    "    video_id = get_video_id(youtube_url)\n",
    "\n",
    "    if video_id:\n",
    "        transcript_text = download_transcript(video_id)\n",
    "        if transcript_text:\n",
    "            video_title = get_video_title(video_id)\n",
    "            file_name = f\"{video_id}_{video_title}.txt\"\n",
    "            file_name = re.sub(r'[\\\\/*?:\"<>|]', '', file_name)  # Remove invalid characters\n",
    "\n",
    "            with open(file_name, 'w', encoding='utf-8') as file:\n",
    "                file.write(transcript_text)\n",
    "\n",
    "            print(f\"Transcript saved to {file_name}\")\n",
    "        else:\n",
    "            print(\"Unable to download transcript.\")\n",
    "    else:\n",
    "        print(\"Invalid YouTube URL.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93606e-1d5f-4d30-ae94-283c1a8e3893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317dc758-74b2-42b2-ad45-218098c2d551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44d399-1169-4a20-b7c9-fad928728f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
